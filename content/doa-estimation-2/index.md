---
title: "Detecci贸n de escapes modificados: implementaci贸n"
draft: false
date: 2025-01-10
description: "Deep-dive en un algoritmo de estimaci贸n de direcci贸n de arribo e implementaci贸n."
tags:
  - doa-estimation
  - signal-processing
---


Partiendo del posteo anterior, y recapitulando el algoritmo, hoy vamos a implementar lo siguiente:

1. Aplicar la transformada de Fourier sobre ventanas solapadas de tiempo de las se帽ales de los micr贸fonos
2. Buscamos las zonas de frecuencia donde hay s贸lo una fuente
3. Aplicamos la detecci贸n de origen de direcci贸n de arribo en cada zona
4. Juntamos las predicciones y consolidamos las estimaciones de los or铆genes 

La idea es poder tomarnos un tiempo para entender c贸mo funciona el algoritmo de detecci贸n de direcci贸n de arribo, tanto de la parte de implementaci贸n como en la derivaci贸n matem谩tica donde se pueda (para mi humilde cerebro de ingeniero y no matem谩tico).

### Notas sobre los snippets de c贸digo

Model茅 el detector como una clase para poder agrupar m谩s f谩cilmente los par谩metros compartidos entre las funciones. Me gusta pensar el detector como un objeto que se instancia al principio del programa y a medida que llegan observaciones se corre sobre lo nuevo:

```python
detector = Detector(parameters..)
while signals := microphone_array.receive():
    detector.detect(signals)
```

De esta manera, las funciones internas pueden s贸lo recibir los datos nuevos y argumentos que cambien con cada c谩lculo, pero los par谩metros del detector (como las posiciones de los micr贸fonos, la velocidad del sonido, la cantidad de bins en los histogramas) no son necesarios de explicitar cada vez. A nivel conceptual, el objeto con los par谩metros representa la configuraci贸n del hardware y eso es inmutable, mientras que las se帽ales cambian en el tiempo.

El c贸digo del resto del post va a tener usos a `self` por esto mismo; si no est谩 indentado es porque est谩 en el c贸digo principal de detecci贸n, caso contrario ser谩n funciones aparte de la clase. 

### Procesando las se帽ales de los micr贸fonos

Al recibir las se帽ales de los micr贸fonos vamos a tener una lista de se帽ales de tama帽o $M$. Cada se帽al en s铆 misma va a ser un vector de longitud $T \cdot f_s$, $T$ siendo el tiempo total de la grabaci贸n (ventana m贸vil en caso de detecci贸n de tiempo real) y $f_s$ la frecuencia de sampleo. Fundamentalmente, es un vector de valores reales, as铆 que para obtener la FFT podemos usar `rfft` que es un poco m谩s r谩pido que el m茅todo general y no devuelve las frecuencias negativas.

Si el arreglo de se帽ales lo recibimos en `mic_signals`, procedemos a obtener las ventanas de tiempo superpuestas -- buscamos aplicar la FFT sobre ventanas de aprox 2048 elementos, y queremos que haya solapamiento entre una ventana y la subsiguiente -- y luego calculamos las transformadas:


```python
self.mic_time_slices = []
for mic_i, signal in enumerate(self.mic_signals):
    self.mic_time_slices.append(list())
    # La funci贸n `overlapping_slices` nos genera los intervalos [a, b], [c, d], etc
    # tal que entre dos consecutivos siempre haya un solapamiento fijo y que cada
    # intervalo tenga el tama帽o pedido. p.ej. b-c = overlap_size; b-a=slice_size.
    for start, stop in overlapping_slices(
        self.parameters.slice_size, self.parameters.overlap_size, len(signal)
    ):
        self.mic_time_slices[mic_i].append(signal[start:stop])

self.mic_fft_slices = [
    [scipy.fft.rfft(_slice) for _slice in slices]
    for slices in self.mic_time_slices
]

self.freq_bins = scipy.fft.rfftfreq(
    self.parameters.slice_size, 1 / self.parameters.sampling_frequency
)
```

Ahora que tenemos la descomposici贸n en frecuencias para cada ventana de tiempo de la informaci贸n que llega a cada micr贸fono, vamos a analizar las zonas de frecuencias para detectar las fuentes de sonido.


### Definici贸n de zona de una sola fuente

La idea de la estrategia es transformar un algoritmo de detecci贸n de una sola fuente en uno que pueda detectar m煤ltiples. Para esto primero detecta en qu茅 zonas hay una sola fuente y luego opera el algoritmo sobre ellas. 

Definimos cada zona $\Omega$ como algunas bandas de frecuencia $\omega$ contiguas, por ejemplo, seis frecuencias contiguas de los bins de la FFT (`freq_bins`). Teniendo esta definici贸n, podemos calcular la covarianza _entre dos micr贸fonos_ en una zona de frecuencias de la siguiente de manera:

$$R_{i,j}^\prime(\Omega) \overset{\underset{\mathrm{def} }{}}{=} \sum_{\omega\in\Omega} \left| X_i(\omega)\cdot X_j(\omega)\right|$$

Como va a haber zonas de mayor intensidad y de menos, necesitamos normalizar para poder tener un criterio uniforme de detecci贸n. Para esto armamos un coeficiente de correlaci贸n, o sea una covarianza divididas las varianzas[^1]:

[^1]: Con la salvaguarda de que son covarianzas y correlaciones usando L1 y no L2.

$$r^\prime_{i,j} (\Omega) \overset{\underset{\mathrm{def} }{}}{=}
\frac{R\_{i,j}^\prime(\Omega)}{\sqrt{R\_{i,i}^\prime(\Omega)\cdot R\_{j,j}^\prime(\Omega)}}$$

Ahora el criterio de detecci贸n es que el promedio a lo largo de todo el array de micr贸fonos de la correlaci贸n entre las observaciones de un micr贸fono y el adyacente sea mayor a cierto l铆mite:

$$\bar{r^\prime} (\Omega)  \geq 1 - \epsilon$$

En definitiva, implementando las ecuaciones y teniendo en cuenta que el an谩lisis siempre es para la ventana de tiempo actual, nos queda un c贸digo como el siguiente:

```python
def covariance(
    self, 
    mic1: int, 
    mic2: int, 
    timestep: int, 
    f_from: int, 
    f_to: int, 
    mic_fft_slices: list,
):
    return np.linalg.norm(
        mic_fft_slices[mic1][timestep][f_from:f_to]
        * mic_fft_slices[mic2][timestep][f_from:f_to],
        ord=1,
    )
def correlation_coefficient(
    self,
    mic1: int,
    mic2: int,
    timestep: int,
    f_from: int,
    f_to: int,
    mic_fft_slices: list,
):
    # Covarianza entre dos micr贸fonos
    cov = self.covariance(mic1, mic2, timestep, f_from, f_to, mic_fft_slices)

    # Normalizando con la varianza de cada micr贸fono
    coeff = cov / np.sqrt(
        self.covariance(
            mic1,
            mic1,
            timestep=timestep,
            f_from=f_from,
            f_to=f_to,
            mic_fft_slices=mic_fft_slices,
        )
        * self.covariance(
            mic2,
            mic2,
            timestep=timestep,
            f_from=f_from,
            f_to=f_to,
            mic_fft_slices=mic_fft_slices,
        )
    )
    return coeff
```

Y el criterio nos queda:

```python
def is_single_source_zone(
    self, zone_index: int, timestep: int, mic_fft_slices: list
) -> bool:
    avg = 0
    omega_index = self.parameters.adjacent_zone * zone_index
    for i in range(self.parameters.num_mics):
        next_mic = (i + 1) % self.parameters.num_mics
        avg += (
            (1 / self.parameters.num_mics)
            * self.correlation_coefficient(
                i,
                next_mic,
                timestep,
                omega_index,
                omega_index + self.parameters.adjacent_zone - 1,
                mic_fft_slices,
            )
        )
    return avg >= self.parameters.single_source_threshold
```

### Detecci贸n de direcci贸n en la zona

Ahora s铆, debemos definir c贸mo se calcula la direcci贸n de arribo de se帽al sabiendo que para cierto intervalo de tiempo y en ciertas frecuencias s贸lo tenemos una fuente. Para esto tenemos que hacer un poco m谩s de matem谩tica . Partamos del objetivo a maximizar para tener la idea general y vayamos incluyendo las definiciones del paper:

$$\hat{\theta}_\omega = \underset{0\leq \theta \lt 2\pi}{\mathrm{argmax}} \left | \mathrm{CICS}^{(\omega)} (\phi) \right |$$

Enchufamos la definici贸n de CICS:

$$\hat{\theta}\_\omega = 
\underset{0\leq \theta \lt 2\pi}{\mathrm{argmax}} 
\left | \
\sum_{i=1}^M G_{m_i\to m_1}^{(\omega)} (\phi) G_{m_im_{i+1}}(\omega)
\right |$$

El primer componente son los _Phase Rotation Factors_ que s贸lo dependen de la geometr铆a del conjunto de micr贸fonos y de la frecuencia a analizar:

$$
G_{m_i\to m_1}^{(\omega)} (\phi) 
\overset{\underset{\mathrm{def} }{}}{=}
\exp\{-j\omega \tau_{m_i\to m_1}(\phi)\}
$$
Ese $\tau$ es la diferencia entre el delay de las se帽ales observado en $\{m_1m_2\}$ y en $\{m_im_{i+1}\}$:

$$\tau_{m_i\to m_1}(\phi)
\overset{\underset{\mathrm{def} }{}}{=}
\tau_{m_1m_2}(\phi) - \tau_{m_im_{i+1}}(\phi)
$$

Que, usando la definici贸n del delay entre dos micr贸fonos adyacentes:

$$\tau_{m_im_{i+1}} (\theta)
\overset{\underset{\mathrm{def} }{}}{=}
l\sin (A + \frac{\pi}{2} - \theta + (i-1) \alpha)/c$$


Ese $/c$ est谩 tal cual del paper y un poco me pone nervioso que no haya sido acompa帽ante del $l$  pero en el an谩lisis dimensional se entiende que no podr铆a ser de otra manera para que la cuenta tenga unidad de tiempo. En fin, digresi贸n aparte, usamos esa definici贸n para los componentes:

$$\tau_{m_i\to m_1}(\phi) =
\frac{l}{c} \left(
    \sin (A + \frac{\pi}{2} - \phi + (1-1) \alpha)
    - \sin (A + \frac{\pi}{2} - \phi + (i-1) \alpha)
\right)
$$

$$\tau_{m_i\to m_1}(\phi) =
\frac{l}{c} \left(
    \sin (A + \frac{\pi}{2} - \phi)
    - \sin (A + \frac{\pi}{2} - \phi + (i-1) \alpha)
\right)
$$
y s贸lo por gusto si definimos $A^\prime \overset{\underset{\mathrm{def} }{}}{=} A + \frac{\pi}{2}$:

$$\tau_{m_i\to m_1}(\phi) =
\frac{l}{c} \left(
    \sin (A^\prime - \phi)
    - \sin (A^\prime - \phi + (i-1) \alpha)
\right)
$$

Bien! Primera parte lista:

$$G_{m_i\to m_1}^{(\omega)} (\phi) =
\exp\left(-j\omega \frac{l}{c} \left(
    \sin (A^\prime - \phi)
    - \sin (A^\prime - \phi + (i-1) \alpha)
\right)\right)$$

Vamos ahora con la otra definici贸n, que es m谩s directa:

$$G_{m_im_{i+1}}(\omega) = \frac{X_i(\omega) \cdot X_{i+1}^\*(\omega)}{\left|X_i(\omega) \cdot X_{i+1}^*(\omega)\right|}$$

(Esta parte es la que m谩s me hace ruido porque en el paper original de los arrays circulares de micr贸fonos se usa otra definici贸n. Adem谩s, hacen distinci贸n entre $\phi$ y $\theta$, cosa que en este paper parece inconsistente. En el funcional original de CICS est谩n _ambos_ como par谩metros y reci茅n luego usan $\phi = \theta$ en la maximizaci贸n, pero este componente queda distinto. En fin, por ahora usamos como est谩 en este paper y despu茅s veremos si hay que cambiarlo -- puede haber habido alg煤n error al redactar la publicaci贸n.) 

Entonces nos queda:

$$\hat{\theta}\_\omega = 
\underset{0\leq \theta \lt 2\pi}{\mathrm{argmax}} 
\left | \
\sum_{i=1}^M 
\exp\left(-j\omega \frac{l}{c} \left(
    \sin (A^\prime - \phi)
    - \sin (A^\prime - \phi + (i-1) \alpha)
\right)\right)
\frac{X_i(\omega) \cdot X_{i+1}^\*(\omega)}{\left|X_i(\omega) \cdot X_{i+1}^*(\omega)\right|}
\right |$$

Por 煤ltimo para implementar el bicho, como generalmente los m茅todos de optimizaci贸n son de minimizaci贸n y nosotros buscamos maximizar, metemos un $-1$ por ah铆 para que d茅 bien el sentido. Ah铆 vamos:

```python
def negative_cics(
  self,
  phi: float,
  omega_index: int,
  t: int,
  mic_fft_slices: list,
  freq_bins: typing.Sequence,
):
  """Negative Circular Integrated Cross Spectrum"""
  value = 0
  omega = freq_bins[omega_index]
  for i in range(self.parameters.num_mics):
      phase_rotation_factor = np.exp(
          -1j
          * omega
          * (self.parameters.distance_to_next_mic / self.parameters.speed_of_sound)
          * (
              np.sin(self.parameters.A_prime - phi)
              - np.sin(
                  self.parameters.A_prime
                  - phi
                  # Agregamos un +1 porque el c贸digo indexa comenzando en 0
                  + (i + 1 - 1) * self.parameters.angle_rotation
              )
          )
      )
      # Pegamos la vuelta en el 煤ltimo micr贸fono
      cross_power = mic_fft_slices[i][t][omega_index] * np.conj(
          mic_fft_slices[((i + 1) % self.parameters.num_mics)][t][omega_index]
      )

      phase_cross_spectrum = cross_power / np.abs(cross_power)
      value += phase_cross_spectrum * phase_rotation_factor
  return -np.abs(value)
```

隆Fiuf!

### Consolidaci贸n de estimaciones

Con la secci贸n anterior ya tenemos un funcional que podemos minimizar para poder encontrar _una_ estimaci贸n de direcci贸n de arribo. Pero, de base, tenemos varias zonas de frecuencia y ventanas de tiempo. Esta secci贸n trabaja en c贸mo se generan esas estimaciones y c贸mo se juntan hasta tener un solo conjunto de predicciones.

De base, uno de los trucos es que en realidad se hace la estimaci贸n anterior varias veces por cada zona. Se toman las $d$ frecuencias m谩s importantes:

```python
def d_highest_peaks(self, freq_from, freq_to, timestep, d, mic_fft_slices):
  magnitudes = {}
  for freq in range(freq_from, freq_to):
      val = 0
      for i in range(self.parameters.num_mics):
          next_mic = (i + 1) % self.parameters.num_mics
          val += np.abs(
              mic_fft_slices[i][timestep][freq]
              * np.conj(mic_fft_slices[next_mic][timestep][freq])
          )
      magnitudes[freq] = val
  return sorted(magnitudes, key=magnitudes.__getitem__)[-d:]
```

Y ahora podemos escribir el loop principal de la detecci贸n. Se toman varias ventanas de tiempo para acumular estimaciones (por ejemplo, analizando 1 segundo en total), y se analiza en cada una las zonas de frecuencia definidas. Entonces:

1. Se consideran s贸lamente las zonas donde hay una sola fuente.
2. Se seleccionan las $d$ frecuencias m谩s importantes de la zona en la ventana de tiempo.
3. Para cada frecuencia importante, se hace la maximizaci贸n del m贸dulo de CICS.
4. Se guardan las estimaciones en una lista para luego analizar.

Adem谩s, agregu茅 un chequeo de que la frecuencia importante siga teniendo un valor importante en la FFT. En el paper no se inclu铆a, pero me daba que se estaban incluyendo muchas frecuencias de muy baja magnitud en vez de considerar las frecuencias importantes. (Historia distinta habr铆a sido si las $d$ frecuencias importantes se hicieran a lo largo de todas las zonas, pero no parece ser el caso.) El c贸digo quedar铆a:

```python 
for t in range(t_from, t_to):
  for zone in range(50):
      if not self.is_single_source_zone(zone, t, self.mic_fft_slices):
          continue

      top_frequency_indices = self.d_highest_peaks(
          zone * self.parameters.adjacent_zone,
          (zone + 1) * self.parameters.adjacent_zone - 1,
          timestep=t,
          d=self.parameters.estimations_per_zone,
          mic_fft_slices=self.mic_fft_slices,
      )

      for frequency_index in top_frequency_indices:
          # Additionally - to avoid spurious DoA estimations
          if np.abs(self.mic_fft_slices[1][t][frequency_index]) < 100:
              continue
          logging.info(
              f"Using frequency {self.freq_bins[frequency_index]} in zone #{zone}"
          )
          self.frequencies_of_interest.append(self.freq_bins[frequency_index])
          logging.debug(
              f"Value: {np.abs(self.mic_fft_slices[1][t][frequency_index])}"
          )
          # for single source zone, detect DoA
          result = scipy.optimize.minimize_scalar(
              self.negative_cics,
              method="bounded",
              bounds=(0, 2 * np.pi),
              args=(frequency_index, t, self.mic_fft_slices, self.freq_bins),
          )
          logging.info(
              f"Frequency {self.freq_bins[frequency_index]} in zone #{zone}"
              f" is voting for angle {np.rad2deg(result.x)}deg"
          )
          self.doa_zone_estimations.append(result.x)
```


### Predicci贸n

La idea de hacer muchas estimaciones r谩pidas es poder tener en el caso m谩s repetido estimaciones correctas. Para eso se analiza el histograma, con la idea de analizar los picos:

```python
self.bins, self.x = np.histogram(
    np.rad2deg(np.array(self.doa_zone_estimations)),
    bins=np.linspace(0, 360, self.parameters.histogram_bins + 1),
)
```

Ahora, no es s贸lo cuesti贸n de sacar los picos m谩s altos porque es posible que una fuente que viene del 谩ngulo de $140^\circ$ se haya estimado con valores $130^\circ$, $145^\circ$, etc, para cada una de las frecuencias que componen la se帽al. Por eso, es necesario eliminar la contribuci贸n de esa fuente al histograma. La estrategia ac谩 es similar a la de _Matching Pursuit_; si pensamos al histograma como una suma contribuciones de fuentes m谩s un poco de ruido, lo que podemos hacer es ir detectando esas fuentes y restar su contribuci贸n hasta quedarnos s贸lo con el ruido.  Por ejemplo:

{{< img
  src="atoms.png"
  alt="Histograma con las estimaciones de arribo y una fuente detectada"
  width="100"
  caption="El primer histograma muestra la consolidaci贸n de todas las estimaciones, para todas las frecuencias de inter茅s, para todas las zonas de una sola fuente, sobre varias ventanas de tiempo consecutivas. Se ve que hay actividad sobre todos los 谩ngulos, pero con monta帽as concentradas en distintos picos. En la segunda figura se detecta no s贸lo el pico sino tambi茅n la contribuci贸n de ese pico al histograma. El siguiente paso es eliminar esa contribuci贸n al histograma y seguir buscando fuentes de sonido. Figura tomada de Pavlidi et al. (2013)." >}}

Primero definimos una contribuci贸n base con forma de una ventana de Blackman (el tama帽o es un par谩metro ). Calculamos todas las contribuciones posibles, es decir, tener una ventana en cada posici贸n del histograma.

```python
window = scipy.signal.windows.blackman(self.parameters.Q)
u = np.zeros(self.parameters.histogram_bins)
u[: self.parameters.Q] = window
c = np.roll(u, -self.parameters.Q0)
C = np.array([np.roll(c, k) for k in range(self.parameters.histogram_bins)])
```

La idea ahora es en cada paso calcular cu谩l de esas contribuciones posibles correlaciona m谩s con el histograma y restar esa ventana hasta que el tama帽o de la correlaci贸n sea por debajo de un umbral -- es decir, que lo que quede sea b谩sicamente ruido. La correlaci贸n, como siempre, queda como un producto interno. En este caso, como tenemos la matriz con todas las transposiciones posibles de la ventana de contribuci贸n, tenemos el producto $C \mathbf{y}$ que nos da un vector de correlaciones. Cada correlaci贸n nos dice la intensidad con la que el histograma $\mathbf{y}$ calza con la transposici贸n de la ventana de Blackman. Como el algoritmo es iterativo, el histograma se va a ir actualizando a medida que restamos las contribuciones ya encontradas, de mayor a menor.




```python
current_histogram = self.bins
self.atoms = []
self.atom_energies = []
self.window_energy = np.dot(c, c)
self.energy_threshold = self.bins.mean()
self.atom_contributions = []
for j in range(self.parameters.max_sources):
    # El paper original incluye una condici贸n de que las fuentes de sonido deben 
    # estar a cierta distancia entre s铆 de m铆nima, pero ac谩 lo obviamos porque la
    # eliminaci贸n de la contribuci贸n ya deber铆a encargarse de eso.
    corr_window = C.dot(current_histogram)
    position = np.argmax(corr_window)
    # Condici贸n de corte: el nuevo pico es de baja intensidad
    atom_energy = corr_window.max() / self.window_energy
    if atom_energy < self.energy_threshold:
        break
    atom_contribution = C[position, :] * atom_energy
    # Eliminamos la contribuci贸n de la fuente actual al histograma y seguimos iterando.
    current_histogram = current_histogram - atom_contribution
    self.atoms.append(position)
    self.atom_energies.append(atom_energy)
    self.atom_contributions.append(atom_contribution)
```

隆De esta manera obtenemos tanto la cantidad de las fuentes como las posiciones de cada una!

### Conclusiones


El objetivo de este post era hacer una revisi贸n en profundidad de c贸mo puede funcionar un algoritmo de detecci贸n de direcci贸n de arribo, tanto viendo la matem谩tica como una implementaci贸n. Reconozco que la parte m谩s misteriosa sigue siendo el desarrollo de la ecuaci贸n de $\mathrm{CICS}$ -- la definici贸n surge de otro paper, de otro equipo, de hace varios a帽os y toman un par de diferencias -- pero a grandes rasgos la idea de tomar un m茅todo que s贸lo funciona para _una_ sola fuente y generalizarlo me parece que queda mucho m谩s clara ahora. De hecho, queda tan modularizado que es posible reemplazar ese m茅todo puntual por otro, siempre que mantenga hip贸tesis semejantes al actual.

El siguiente texto tiene como objetivo mostrar los resultados de este m茅todo y compararlo con otros disponibles en bibliotecas para poder llegar a unas conclusiones :-) 